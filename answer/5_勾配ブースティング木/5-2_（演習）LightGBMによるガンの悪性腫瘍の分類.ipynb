{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1rZlY2-ubRTvh-q2IC6ygLqEdcwSdJtDf",
   "authorship_tag": "ABX9TyPPrs6tRLU++1oXdHsS8HZg"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "id": "f1f5e1bc",
   "cell_type": "markdown",
   "source": "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trainocate-japan/Machine-Learning-and-Deep-Learning-Hands-on/blob/main/answer/5_勾配ブースティング木/5-2_（演習）LightGBMによるガンの悪性腫瘍の分類.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0C3IpJk59aJ"
   },
   "source": "# 5-2_（演習）LightGBMによるガンの悪性腫瘍の分類\nこちらはロジスティック回帰で扱っているガンの悪性腫瘍判定と学習を開始するまで同じプログラムになっています。（LightGBM・交差検証・グリッドサーチ用のライブラリインポートは除く）\n\n※ ただし、決定木系のアルゴリズムではスケールをそろえる必要がないため、ロジスティック回帰モデルで精度改善のために行っていた標準化は行いません。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKgM2zMPFmBe"
   },
   "source": "## ライブラリのインポート"
  },
  {
   "cell_type": "code",
   "source": "# データを処理するための基本的なライブラリ\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report",
   "metadata": {
    "id": "TSZt_9MljRt4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295615943,
     "user_tz": -540,
     "elapsed": 2055,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# LightGBMモデルをインポート\nfrom lightgbm import LGBMClassifier",
   "metadata": {
    "id": "H7m529CujSpR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295615944,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Dzy0hJeTUZv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295621891,
     "user_tz": -540,
     "elapsed": 5952,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "ee0c4264-5da5-4cfe-b009-ec87332d15cb"
   },
   "source": "# matplotlibで日本語表示するための設定\n!pip install japanize_matplotlib | tail -n 1\nimport japanize_matplotlib",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successfully installed japanize-matplotlib-1.1.3\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ-6ZutoLMUs"
   },
   "source": "Google Colaboratory上での出力のデフォルト設定"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tH0i-1XNLEbe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295621891,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "source": "# pandasのDataframeの出力\npd.set_option('display.max_columns', 500) # 表示列の最大\npd.set_option('display.max_rows', 500) # 表示行の最大\npd.set_option('display.unicode.east_asian_width', True) # 日本語出力時にヘッダのずれを解消\npd.options.display.float_format = '{:,.5f}'.format # 表示桁数の設定\n\n# ノートブックの表示桁数設定。この設定はprint文には作用せず、セルの最後に書いたものを出力する際に適用されます。\n%precision 3\n# numpy配列の指数表示禁止設定\nnp.set_printoptions(suppress=True)\n# numpy配列の表示桁数設定\nnp.set_printoptions(precision=3)",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgUVJd2FcT45"
   },
   "source": "## データの準備\n今回使用するデータはscikit-learnからもデータセットとして利用することができる、UCI ML Breast Cancer Wisconsin (Diagnostic) datasetsのコピーです。<br>\nUCI Machine Learning Repositoryから公開されています。<br>\ndownloaded from : https://goo.gl/U2Uwz2\n\nデータセットについての説明はこちらに記載されています。<br>\nhttps://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
  },
  {
   "cell_type": "markdown",
   "source": "#### データを取り込む\n- pandasのread_csvメソッドを使用して、mlho/data/cancer.csvファイルを読み込みます\n- 読み込んだものは変数df_cancerに代入します",
   "metadata": {
    "id": "xVdGz4qH40Bd"
   }
  },
  {
   "cell_type": "code",
   "source": "# csvファイルを読み込みます\ndf_cancer = pd.read_csv(\"/content/drive/MyDrive/mlho/data/cancer.csv\")",
   "metadata": {
    "id": "Id6S1tvV1jB5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622304,
     "user_tz": -540,
     "elapsed": 416,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### データを確認する",
   "metadata": {
    "id": "UzbVEi9b48VC"
   }
  },
  {
   "cell_type": "code",
   "source": "# 読み込んだデータを確認します\n# Classが目的変数になる腫瘍の悪性または良性を表しています。（0:悪性、1:良性）\ndf_cancer.head()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "yL_ybysA1-di",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622304,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "45ad1547-c056-4398-b384-6602b69ce0f1"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n0     17.99000      10.38000       122.80000 1,001.00000          0.11840   \n1     20.57000      17.77000       132.90000 1,326.00000          0.08474   \n2     19.69000      21.25000       130.00000 1,203.00000          0.10960   \n3     11.42000      20.38000        77.58000   386.10000          0.14250   \n4     20.29000      14.34000       135.10000 1,297.00000          0.10030   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760         0.30010              0.14710        0.24190   \n1           0.07864         0.08690              0.07017        0.18120   \n2           0.15990         0.19740              0.12790        0.20690   \n3           0.28390         0.24140              0.10520        0.25970   \n4           0.13280         0.19800              0.10430        0.18090   \n\n   mean fractal dimension  radius error  texture error  perimeter error  \\\n0                 0.07871       1.09500        0.90530          8.58900   \n1                 0.05667       0.54350        0.73390          3.39800   \n2                 0.05999       0.74560        0.78690          4.58500   \n3                 0.09744       0.49560        1.15600          3.44500   \n4                 0.05883       0.75720        0.78130          5.43800   \n\n   area error  smoothness error  compactness error  concavity error  \\\n0   153.40000           0.00640            0.04904          0.05373   \n1    74.08000           0.00522            0.01308          0.01860   \n2    94.03000           0.00615            0.04006          0.03832   \n3    27.23000           0.00911            0.07458          0.05661   \n4    94.44000           0.01149            0.02461          0.05688   \n\n   concave points error  symmetry error  fractal dimension error  \\\n0               0.01587         0.03003                  0.00619   \n1               0.01340         0.01389                  0.00353   \n2               0.02058         0.02250                  0.00457   \n3               0.01867         0.05963                  0.00921   \n4               0.01885         0.01756                  0.00511   \n\n   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n0      25.38000       17.33000        184.60000 2,019.00000           0.16220   \n1      24.99000       23.41000        158.80000 1,956.00000           0.12380   \n2      23.57000       25.53000        152.50000 1,709.00000           0.14440   \n3      14.91000       26.50000         98.87000   567.70000           0.20980   \n4      22.54000       16.67000        152.20000 1,575.00000           0.13740   \n\n   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n0            0.66560          0.71190               0.26540         0.46010   \n1            0.18660          0.24160               0.18600         0.27500   \n2            0.42450          0.45040               0.24300         0.36130   \n3            0.86630          0.68690               0.25750         0.66380   \n4            0.20500          0.40000               0.16250         0.23640   \n\n   worst fractal dimension  Class  \n0                  0.11890      0  \n1                  0.08902      0  \n2                  0.08758      0  \n3                  0.17300      0  \n4                  0.07678      0  ",
      "text/html": "\n  <div id=\"df-36e0d891-e5a4-4b31-b2f9-2bf51c835094\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>radius error</th>\n      <th>texture error</th>\n      <th>perimeter error</th>\n      <th>area error</th>\n      <th>smoothness error</th>\n      <th>compactness error</th>\n      <th>concavity error</th>\n      <th>concave points error</th>\n      <th>symmetry error</th>\n      <th>fractal dimension error</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99000</td>\n      <td>10.38000</td>\n      <td>122.80000</td>\n      <td>1,001.00000</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.24190</td>\n      <td>0.07871</td>\n      <td>1.09500</td>\n      <td>0.90530</td>\n      <td>8.58900</td>\n      <td>153.40000</td>\n      <td>0.00640</td>\n      <td>0.04904</td>\n      <td>0.05373</td>\n      <td>0.01587</td>\n      <td>0.03003</td>\n      <td>0.00619</td>\n      <td>25.38000</td>\n      <td>17.33000</td>\n      <td>184.60000</td>\n      <td>2,019.00000</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.71190</td>\n      <td>0.26540</td>\n      <td>0.46010</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57000</td>\n      <td>17.77000</td>\n      <td>132.90000</td>\n      <td>1,326.00000</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.18120</td>\n      <td>0.05667</td>\n      <td>0.54350</td>\n      <td>0.73390</td>\n      <td>3.39800</td>\n      <td>74.08000</td>\n      <td>0.00522</td>\n      <td>0.01308</td>\n      <td>0.01860</td>\n      <td>0.01340</td>\n      <td>0.01389</td>\n      <td>0.00353</td>\n      <td>24.99000</td>\n      <td>23.41000</td>\n      <td>158.80000</td>\n      <td>1,956.00000</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.24160</td>\n      <td>0.18600</td>\n      <td>0.27500</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69000</td>\n      <td>21.25000</td>\n      <td>130.00000</td>\n      <td>1,203.00000</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.20690</td>\n      <td>0.05999</td>\n      <td>0.74560</td>\n      <td>0.78690</td>\n      <td>4.58500</td>\n      <td>94.03000</td>\n      <td>0.00615</td>\n      <td>0.04006</td>\n      <td>0.03832</td>\n      <td>0.02058</td>\n      <td>0.02250</td>\n      <td>0.00457</td>\n      <td>23.57000</td>\n      <td>25.53000</td>\n      <td>152.50000</td>\n      <td>1,709.00000</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.45040</td>\n      <td>0.24300</td>\n      <td>0.36130</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42000</td>\n      <td>20.38000</td>\n      <td>77.58000</td>\n      <td>386.10000</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.25970</td>\n      <td>0.09744</td>\n      <td>0.49560</td>\n      <td>1.15600</td>\n      <td>3.44500</td>\n      <td>27.23000</td>\n      <td>0.00911</td>\n      <td>0.07458</td>\n      <td>0.05661</td>\n      <td>0.01867</td>\n      <td>0.05963</td>\n      <td>0.00921</td>\n      <td>14.91000</td>\n      <td>26.50000</td>\n      <td>98.87000</td>\n      <td>567.70000</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.68690</td>\n      <td>0.25750</td>\n      <td>0.66380</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29000</td>\n      <td>14.34000</td>\n      <td>135.10000</td>\n      <td>1,297.00000</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.18090</td>\n      <td>0.05883</td>\n      <td>0.75720</td>\n      <td>0.78130</td>\n      <td>5.43800</td>\n      <td>94.44000</td>\n      <td>0.01149</td>\n      <td>0.02461</td>\n      <td>0.05688</td>\n      <td>0.01885</td>\n      <td>0.01756</td>\n      <td>0.00511</td>\n      <td>22.54000</td>\n      <td>16.67000</td>\n      <td>152.20000</td>\n      <td>1,575.00000</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.40000</td>\n      <td>0.16250</td>\n      <td>0.23640</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36e0d891-e5a4-4b31-b2f9-2bf51c835094')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n        \n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\">\n    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n  </svg>\n      </button>\n      \n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n      <script>\n        const buttonEl =\n          document.querySelector('#df-36e0d891-e5a4-4b31-b2f9-2bf51c835094 button.colab-df-convert');\n        buttonEl.style.display =\n          google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n        async function convertToInteractive(key) {\n          const element = document.querySelector('#df-36e0d891-e5a4-4b31-b2f9-2bf51c835094');\n          const dataTable =\n            await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                     [key], {});\n          if (!dataTable) return;\n\n          const docLinkHtml = 'Like what you see? Visit the ' +\n            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n            + ' to learn more about interactive tables.';\n          element.innerHTML = '';\n          dataTable['output_type'] = 'display_data';\n          await google.colab.output.renderOutput(dataTable, element);\n          const docLink = document.createElement('div');\n          docLink.innerHTML = docLinkHtml;\n          element.appendChild(docLink);\n        }\n      </script>\n    </div>\n  </div>\n  "
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# df_cancerのデータ要約を確認\ndf_cancer.info()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stmJSzwi4aNi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622603,
     "user_tz": -540,
     "elapsed": 304,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "9ee2664e-d755-491b-f1ec-a04a76eae6fe"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 31 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   mean radius              569 non-null    float64\n 1   mean texture             569 non-null    float64\n 2   mean perimeter           569 non-null    float64\n 3   mean area                569 non-null    float64\n 4   mean smoothness          569 non-null    float64\n 5   mean compactness         569 non-null    float64\n 6   mean concavity           569 non-null    float64\n 7   mean concave points      569 non-null    float64\n 8   mean symmetry            569 non-null    float64\n 9   mean fractal dimension   569 non-null    float64\n 10  radius error             569 non-null    float64\n 11  texture error            569 non-null    float64\n 12  perimeter error          569 non-null    float64\n 13  area error               569 non-null    float64\n 14  smoothness error         569 non-null    float64\n 15  compactness error        569 non-null    float64\n 16  concavity error          569 non-null    float64\n 17  concave points error     569 non-null    float64\n 18  symmetry error           569 non-null    float64\n 19  fractal dimension error  569 non-null    float64\n 20  worst radius             569 non-null    float64\n 21  worst texture            569 non-null    float64\n 22  worst perimeter          569 non-null    float64\n 23  worst area               569 non-null    float64\n 24  worst smoothness         569 non-null    float64\n 25  worst compactness        569 non-null    float64\n 26  worst concavity          569 non-null    float64\n 27  worst concave points     569 non-null    float64\n 28  worst symmetry           569 non-null    float64\n 29  worst fractal dimension  569 non-null    float64\n 30  Class                    569 non-null    int64  \ndtypes: float64(30), int64(1)\nmemory usage: 137.9 KB\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# df_cancerの統計情報を確認\ndf_cancer.describe()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "owaePxYS4dOm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622604,
     "user_tz": -540,
     "elapsed": 9,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "220d28f3-61bb-41b6-e2cc-543f6ef9e996"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\ncount    569.00000     569.00000       569.00000   569.00000        569.00000   \nmean      14.12729      19.28965        91.96903   654.88910          0.09636   \nstd        3.52405       4.30104        24.29898   351.91413          0.01406   \nmin        6.98100       9.71000        43.79000   143.50000          0.05263   \n25%       11.70000      16.17000        75.17000   420.30000          0.08637   \n50%       13.37000      18.84000        86.24000   551.10000          0.09587   \n75%       15.78000      21.80000       104.10000   782.70000          0.10530   \nmax       28.11000      39.28000       188.50000 2,501.00000          0.16340   \n\n       mean compactness  mean concavity  mean concave points  mean symmetry  \\\ncount         569.00000       569.00000            569.00000      569.00000   \nmean            0.10434         0.08880              0.04892        0.18116   \nstd             0.05281         0.07972              0.03880        0.02741   \nmin             0.01938         0.00000              0.00000        0.10600   \n25%             0.06492         0.02956              0.02031        0.16190   \n50%             0.09263         0.06154              0.03350        0.17920   \n75%             0.13040         0.13070              0.07400        0.19570   \nmax             0.34540         0.42680              0.20120        0.30400   \n\n       mean fractal dimension  radius error  texture error  perimeter error  \\\ncount               569.00000     569.00000      569.00000        569.00000   \nmean                  0.06280       0.40517        1.21685          2.86606   \nstd                   0.00706       0.27731        0.55165          2.02185   \nmin                   0.04996       0.11150        0.36020          0.75700   \n25%                   0.05770       0.23240        0.83390          1.60600   \n50%                   0.06154       0.32420        1.10800          2.28700   \n75%                   0.06612       0.47890        1.47400          3.35700   \nmax                   0.09744       2.87300        4.88500         21.98000   \n\n       area error  smoothness error  compactness error  concavity error  \\\ncount   569.00000         569.00000          569.00000        569.00000   \nmean     40.33708           0.00704            0.02548          0.03189   \nstd      45.49101           0.00300            0.01791          0.03019   \nmin       6.80200           0.00171            0.00225          0.00000   \n25%      17.85000           0.00517            0.01308          0.01509   \n50%      24.53000           0.00638            0.02045          0.02589   \n75%      45.19000           0.00815            0.03245          0.04205   \nmax     542.20000           0.03113            0.13540          0.39600   \n\n       concave points error  symmetry error  fractal dimension error  \\\ncount             569.00000       569.00000                569.00000   \nmean                0.01180         0.02054                  0.00379   \nstd                 0.00617         0.00827                  0.00265   \nmin                 0.00000         0.00788                  0.00089   \n25%                 0.00764         0.01516                  0.00225   \n50%                 0.01093         0.01873                  0.00319   \n75%                 0.01471         0.02348                  0.00456   \nmax                 0.05279         0.07895                  0.02984   \n\n       worst radius  worst texture  worst perimeter  worst area  \\\ncount     569.00000      569.00000        569.00000   569.00000   \nmean       16.26919       25.67722        107.26121   880.58313   \nstd         4.83324        6.14626         33.60254   569.35699   \nmin         7.93000       12.02000         50.41000   185.20000   \n25%        13.01000       21.08000         84.11000   515.30000   \n50%        14.97000       25.41000         97.66000   686.50000   \n75%        18.79000       29.72000        125.40000 1,084.00000   \nmax        36.04000       49.54000        251.20000 4,254.00000   \n\n       worst smoothness  worst compactness  worst concavity  \\\ncount         569.00000          569.00000        569.00000   \nmean            0.13237            0.25427          0.27219   \nstd             0.02283            0.15734          0.20862   \nmin             0.07117            0.02729          0.00000   \n25%             0.11660            0.14720          0.11450   \n50%             0.13130            0.21190          0.22670   \n75%             0.14600            0.33910          0.38290   \nmax             0.22260            1.05800          1.25200   \n\n       worst concave points  worst symmetry  worst fractal dimension     Class  \ncount             569.00000       569.00000                569.00000 569.00000  \nmean                0.11461         0.29008                  0.08395   0.62742  \nstd                 0.06573         0.06187                  0.01806   0.48392  \nmin                 0.00000         0.15650                  0.05504   0.00000  \n25%                 0.06493         0.25040                  0.07146   0.00000  \n50%                 0.09993         0.28220                  0.08004   1.00000  \n75%                 0.16140         0.31790                  0.09208   1.00000  \nmax                 0.29100         0.66380                  0.20750   1.00000  ",
      "text/html": "\n  <div id=\"df-2ff254a6-3569-4773-b242-dd6a0d3db268\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>radius error</th>\n      <th>texture error</th>\n      <th>perimeter error</th>\n      <th>area error</th>\n      <th>smoothness error</th>\n      <th>compactness error</th>\n      <th>concavity error</th>\n      <th>concave points error</th>\n      <th>symmetry error</th>\n      <th>fractal dimension error</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n      <td>569.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.12729</td>\n      <td>19.28965</td>\n      <td>91.96903</td>\n      <td>654.88910</td>\n      <td>0.09636</td>\n      <td>0.10434</td>\n      <td>0.08880</td>\n      <td>0.04892</td>\n      <td>0.18116</td>\n      <td>0.06280</td>\n      <td>0.40517</td>\n      <td>1.21685</td>\n      <td>2.86606</td>\n      <td>40.33708</td>\n      <td>0.00704</td>\n      <td>0.02548</td>\n      <td>0.03189</td>\n      <td>0.01180</td>\n      <td>0.02054</td>\n      <td>0.00379</td>\n      <td>16.26919</td>\n      <td>25.67722</td>\n      <td>107.26121</td>\n      <td>880.58313</td>\n      <td>0.13237</td>\n      <td>0.25427</td>\n      <td>0.27219</td>\n      <td>0.11461</td>\n      <td>0.29008</td>\n      <td>0.08395</td>\n      <td>0.62742</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.52405</td>\n      <td>4.30104</td>\n      <td>24.29898</td>\n      <td>351.91413</td>\n      <td>0.01406</td>\n      <td>0.05281</td>\n      <td>0.07972</td>\n      <td>0.03880</td>\n      <td>0.02741</td>\n      <td>0.00706</td>\n      <td>0.27731</td>\n      <td>0.55165</td>\n      <td>2.02185</td>\n      <td>45.49101</td>\n      <td>0.00300</td>\n      <td>0.01791</td>\n      <td>0.03019</td>\n      <td>0.00617</td>\n      <td>0.00827</td>\n      <td>0.00265</td>\n      <td>4.83324</td>\n      <td>6.14626</td>\n      <td>33.60254</td>\n      <td>569.35699</td>\n      <td>0.02283</td>\n      <td>0.15734</td>\n      <td>0.20862</td>\n      <td>0.06573</td>\n      <td>0.06187</td>\n      <td>0.01806</td>\n      <td>0.48392</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>6.98100</td>\n      <td>9.71000</td>\n      <td>43.79000</td>\n      <td>143.50000</td>\n      <td>0.05263</td>\n      <td>0.01938</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.10600</td>\n      <td>0.04996</td>\n      <td>0.11150</td>\n      <td>0.36020</td>\n      <td>0.75700</td>\n      <td>6.80200</td>\n      <td>0.00171</td>\n      <td>0.00225</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00788</td>\n      <td>0.00089</td>\n      <td>7.93000</td>\n      <td>12.02000</td>\n      <td>50.41000</td>\n      <td>185.20000</td>\n      <td>0.07117</td>\n      <td>0.02729</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.15650</td>\n      <td>0.05504</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.70000</td>\n      <td>16.17000</td>\n      <td>75.17000</td>\n      <td>420.30000</td>\n      <td>0.08637</td>\n      <td>0.06492</td>\n      <td>0.02956</td>\n      <td>0.02031</td>\n      <td>0.16190</td>\n      <td>0.05770</td>\n      <td>0.23240</td>\n      <td>0.83390</td>\n      <td>1.60600</td>\n      <td>17.85000</td>\n      <td>0.00517</td>\n      <td>0.01308</td>\n      <td>0.01509</td>\n      <td>0.00764</td>\n      <td>0.01516</td>\n      <td>0.00225</td>\n      <td>13.01000</td>\n      <td>21.08000</td>\n      <td>84.11000</td>\n      <td>515.30000</td>\n      <td>0.11660</td>\n      <td>0.14720</td>\n      <td>0.11450</td>\n      <td>0.06493</td>\n      <td>0.25040</td>\n      <td>0.07146</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.37000</td>\n      <td>18.84000</td>\n      <td>86.24000</td>\n      <td>551.10000</td>\n      <td>0.09587</td>\n      <td>0.09263</td>\n      <td>0.06154</td>\n      <td>0.03350</td>\n      <td>0.17920</td>\n      <td>0.06154</td>\n      <td>0.32420</td>\n      <td>1.10800</td>\n      <td>2.28700</td>\n      <td>24.53000</td>\n      <td>0.00638</td>\n      <td>0.02045</td>\n      <td>0.02589</td>\n      <td>0.01093</td>\n      <td>0.01873</td>\n      <td>0.00319</td>\n      <td>14.97000</td>\n      <td>25.41000</td>\n      <td>97.66000</td>\n      <td>686.50000</td>\n      <td>0.13130</td>\n      <td>0.21190</td>\n      <td>0.22670</td>\n      <td>0.09993</td>\n      <td>0.28220</td>\n      <td>0.08004</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15.78000</td>\n      <td>21.80000</td>\n      <td>104.10000</td>\n      <td>782.70000</td>\n      <td>0.10530</td>\n      <td>0.13040</td>\n      <td>0.13070</td>\n      <td>0.07400</td>\n      <td>0.19570</td>\n      <td>0.06612</td>\n      <td>0.47890</td>\n      <td>1.47400</td>\n      <td>3.35700</td>\n      <td>45.19000</td>\n      <td>0.00815</td>\n      <td>0.03245</td>\n      <td>0.04205</td>\n      <td>0.01471</td>\n      <td>0.02348</td>\n      <td>0.00456</td>\n      <td>18.79000</td>\n      <td>29.72000</td>\n      <td>125.40000</td>\n      <td>1,084.00000</td>\n      <td>0.14600</td>\n      <td>0.33910</td>\n      <td>0.38290</td>\n      <td>0.16140</td>\n      <td>0.31790</td>\n      <td>0.09208</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>28.11000</td>\n      <td>39.28000</td>\n      <td>188.50000</td>\n      <td>2,501.00000</td>\n      <td>0.16340</td>\n      <td>0.34540</td>\n      <td>0.42680</td>\n      <td>0.20120</td>\n      <td>0.30400</td>\n      <td>0.09744</td>\n      <td>2.87300</td>\n      <td>4.88500</td>\n      <td>21.98000</td>\n      <td>542.20000</td>\n      <td>0.03113</td>\n      <td>0.13540</td>\n      <td>0.39600</td>\n      <td>0.05279</td>\n      <td>0.07895</td>\n      <td>0.02984</td>\n      <td>36.04000</td>\n      <td>49.54000</td>\n      <td>251.20000</td>\n      <td>4,254.00000</td>\n      <td>0.22260</td>\n      <td>1.05800</td>\n      <td>1.25200</td>\n      <td>0.29100</td>\n      <td>0.66380</td>\n      <td>0.20750</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ff254a6-3569-4773-b242-dd6a0d3db268')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n        \n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\">\n    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n  </svg>\n      </button>\n      \n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n      <script>\n        const buttonEl =\n          document.querySelector('#df-2ff254a6-3569-4773-b242-dd6a0d3db268 button.colab-df-convert');\n        buttonEl.style.display =\n          google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n        async function convertToInteractive(key) {\n          const element = document.querySelector('#df-2ff254a6-3569-4773-b242-dd6a0d3db268');\n          const dataTable =\n            await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                     [key], {});\n          if (!dataTable) return;\n\n          const docLinkHtml = 'Like what you see? Visit the ' +\n            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n            + ' to learn more about interactive tables.';\n          element.innerHTML = '';\n          dataTable['output_type'] = 'display_data';\n          await google.colab.output.renderOutput(dataTable, element);\n          const docLink = document.createElement('div');\n          docLink.innerHTML = docLinkHtml;\n          element.appendChild(docLink);\n        }\n      </script>\n    </div>\n  </div>\n  "
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### 説明変数、目的変数を切り出す",
   "metadata": {
    "id": "Peo1k5kE5DHb"
   }
  },
  {
   "cell_type": "code",
   "source": "# 目的変数にするClass以外をすべて説明変数にする\nx = df_cancer.drop(columns='Class')",
   "metadata": {
    "id": "r8spXOuP4xLI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622604,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "x.head(2)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "npZsC32FBB2N",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622947,
     "user_tz": -540,
     "elapsed": 350,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "7a8e8279-fc69-4f52-fe36-235dfebc8f03"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n0     17.99000      10.38000       122.80000 1,001.00000          0.11840   \n1     20.57000      17.77000       132.90000 1,326.00000          0.08474   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760         0.30010              0.14710        0.24190   \n1           0.07864         0.08690              0.07017        0.18120   \n\n   mean fractal dimension  radius error  texture error  perimeter error  \\\n0                 0.07871       1.09500        0.90530          8.58900   \n1                 0.05667       0.54350        0.73390          3.39800   \n\n   area error  smoothness error  compactness error  concavity error  \\\n0   153.40000           0.00640            0.04904          0.05373   \n1    74.08000           0.00522            0.01308          0.01860   \n\n   concave points error  symmetry error  fractal dimension error  \\\n0               0.01587         0.03003                  0.00619   \n1               0.01340         0.01389                  0.00353   \n\n   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n0      25.38000       17.33000        184.60000 2,019.00000           0.16220   \n1      24.99000       23.41000        158.80000 1,956.00000           0.12380   \n\n   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n0            0.66560          0.71190               0.26540         0.46010   \n1            0.18660          0.24160               0.18600         0.27500   \n\n   worst fractal dimension  \n0                  0.11890  \n1                  0.08902  ",
      "text/html": "\n  <div id=\"df-df1181e7-f16f-4aa3-b413-4c0f1793d073\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>radius error</th>\n      <th>texture error</th>\n      <th>perimeter error</th>\n      <th>area error</th>\n      <th>smoothness error</th>\n      <th>compactness error</th>\n      <th>concavity error</th>\n      <th>concave points error</th>\n      <th>symmetry error</th>\n      <th>fractal dimension error</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99000</td>\n      <td>10.38000</td>\n      <td>122.80000</td>\n      <td>1,001.00000</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.24190</td>\n      <td>0.07871</td>\n      <td>1.09500</td>\n      <td>0.90530</td>\n      <td>8.58900</td>\n      <td>153.40000</td>\n      <td>0.00640</td>\n      <td>0.04904</td>\n      <td>0.05373</td>\n      <td>0.01587</td>\n      <td>0.03003</td>\n      <td>0.00619</td>\n      <td>25.38000</td>\n      <td>17.33000</td>\n      <td>184.60000</td>\n      <td>2,019.00000</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.71190</td>\n      <td>0.26540</td>\n      <td>0.46010</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57000</td>\n      <td>17.77000</td>\n      <td>132.90000</td>\n      <td>1,326.00000</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.18120</td>\n      <td>0.05667</td>\n      <td>0.54350</td>\n      <td>0.73390</td>\n      <td>3.39800</td>\n      <td>74.08000</td>\n      <td>0.00522</td>\n      <td>0.01308</td>\n      <td>0.01860</td>\n      <td>0.01340</td>\n      <td>0.01389</td>\n      <td>0.00353</td>\n      <td>24.99000</td>\n      <td>23.41000</td>\n      <td>158.80000</td>\n      <td>1,956.00000</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.24160</td>\n      <td>0.18600</td>\n      <td>0.27500</td>\n      <td>0.08902</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df1181e7-f16f-4aa3-b413-4c0f1793d073')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n        \n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\">\n    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n  </svg>\n      </button>\n      \n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n      <script>\n        const buttonEl =\n          document.querySelector('#df-df1181e7-f16f-4aa3-b413-4c0f1793d073 button.colab-df-convert');\n        buttonEl.style.display =\n          google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n        async function convertToInteractive(key) {\n          const element = document.querySelector('#df-df1181e7-f16f-4aa3-b413-4c0f1793d073');\n          const dataTable =\n            await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                     [key], {});\n          if (!dataTable) return;\n\n          const docLinkHtml = 'Like what you see? Visit the ' +\n            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n            + ' to learn more about interactive tables.';\n          element.innerHTML = '';\n          dataTable['output_type'] = 'display_data';\n          await google.colab.output.renderOutput(dataTable, element);\n          const docLink = document.createElement('div');\n          docLink.innerHTML = docLinkHtml;\n          element.appendChild(docLink);\n        }\n      </script>\n    </div>\n  </div>\n  "
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "y = df_cancer['Class']",
   "metadata": {
    "id": "evw_fxJH5cDt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622947,
     "user_tz": -540,
     "elapsed": 6,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "y.head(2)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqA7PbxnBCf7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622947,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "8a0de31c-037e-48cd-fe9d-3a02ce6a164b"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0\n1    0\nName: Class, dtype: int64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### データを訓練データと検証データに分割する",
   "metadata": {
    "id": "y7tKbJFv5J-L"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip-zesPflMqD"
   },
   "source": "**本研修でbreast-cancerデータセットを使用する際には、訓練データ70%、random_state=3で固定しています。他のモデルとの比較をしやすくするためです**"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_zilzaBGlMqD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622947,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "source": "# 訓練データと検証データに分割(70%を訓練用に使用)\n# stratifyは指定した列の値が均等に割り振られる\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=3, stratify=y)",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_ymvdFmkX4G"
   },
   "source": "## モデルの定義"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NOGYVyV0Tpc8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295622948,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "source": "model = LGBMClassifier(random_state=0)",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTBg3UdzlZ6M"
   },
   "source": "## モデルの学習"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623596,
     "user_tz": -540,
     "elapsed": 652,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "27219a5d-5e5c-43ba-e290-c7b61ed39743",
    "id": "LRqAGD8SlZ6S"
   },
   "source": "model.fit(train_x, train_y)",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LGBMClassifier(random_state=0)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7K3DpNjkZ-L"
   },
   "source": "## 評価"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYYM2Wo1bT9f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623596,
     "user_tz": -540,
     "elapsed": 11,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "04b97736-1481-4882-d03d-fe886b122d84"
   },
   "source": "# 訓練データで予測精度（正解率）を確認する\nmodel.score(train_x, train_y)",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbLjNOxGUWvs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623596,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "c4c9d457-7969-4edf-9f12-5568b9e2266f"
   },
   "source": "# 検証データで予測精度（正解率）を確認する\nmodel.score(val_x, val_y)",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9649122807017544"
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVAYbI170TH5"
   },
   "source": "## LightGBMのパラメータチューニング"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCIGurc8q2Nz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623597,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "5d0b7887-66e3-4303-ecd3-9c34cc186c7f"
   },
   "source": "# ハイパーパラメータを変えて、精度の変化を確認してみましょう\nmodel = LGBMClassifier(learning_rate=0.1, n_estimators=60, num_leaves=8, random_state=0)\nmodel.fit(train_x, train_y)",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LGBMClassifier(n_estimators=60, num_leaves=8, random_state=0)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1Vm2QfAq2N7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623597,
     "user_tz": -540,
     "elapsed": 6,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "07a4e567-d5c3-4050-f782-30a31557729b"
   },
   "source": "# 訓練データで予測精度（正解率）を確認する\nmodel.score(train_x, train_y)",
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vKABOPCq2N8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623597,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "a7624d75-34fd-484d-ad9f-2ab3de55aaff"
   },
   "source": "# テストデータで予測精度（正解率）を確認する\nmodel.score(val_x, val_y)",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9766081871345029"
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtV9EqeGtqU2"
   },
   "source": "**※ 調整例**\n\n`model = LGBMClassifier(learning_rate=0.1, n_estimators=60, num_leaves=8, random_state=0)`\n\n97%程の精度が出ます。。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qXDRLXwJPhd"
   },
   "source": "## 交差検証とグリッドサーチ"
  },
  {
   "cell_type": "code",
   "source": "# 交差検証とグリッドサーチ用のライブラリをインポート\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV",
   "metadata": {
    "id": "kqm1dGukjcLC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295623597,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VUhdio8rxCCD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666173,
     "user_tz": -540,
     "elapsed": 42580,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "f70e145d-aa6b-4dfe-8de8-82d787cf2e5f"
   },
   "source": "# 探索したいパラメーターをディクショナリで設定する\n\nparam_grid = {\"learning_rate\":[0.1],\n              \"num_leaves\": [6, 7, 8, 9],\n              \"colsample_bytree\": [0.6, 0.8, 1.0],\n              \"subsample\": [0.6, 0.8, 1.0],\n              \"n_estimators\":[50, 60, 70]\n             } \n\n# パラメータチューニングをグリッドサーチ\ngscv = GridSearchCV(estimator = LGBMClassifier(random_state = 0), # パラメータ探索するモデル\n                           param_grid = param_grid, # 探索するパラメータのリスト\n                           cv = 4, # 交差検証のデータの分割数\n                           verbose=2) # ログをどれだけ出力するか。進み具合のわかる2がおすすめ\n\ngscv.fit(x, y)",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.2s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.3s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   2.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   1.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.3s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.7s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.2s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   1.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.6s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.4s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   2.3s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.7s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.3s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   1.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.6s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.6s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.6s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.7s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.6, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=50, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=60, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=6, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=7, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=8, subsample=1.0; total time=   0.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.6; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=0.8; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, n_estimators=70, num_leaves=9, subsample=1.0; total time=   0.1s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=4, estimator=LGBMClassifier(random_state=0),\n             param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n                         'learning_rate': [0.1], 'n_estimators': [50, 60, 70],\n                         'num_leaves': [6, 7, 8, 9],\n                         'subsample': [0.6, 0.8, 1.0]},\n             verbose=2)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGB53NubXk_4"
   },
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "925K6qBgUfXt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666174,
     "user_tz": -540,
     "elapsed": 16,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "4a25e616-43c0-45d9-cc1f-7f8c4b4aa0ba"
   },
   "source": "# スコアの一覧を取得\ngs_result = pd.DataFrame.from_dict(gscv.cv_results_)\ngs_result.sort_values('rank_test_score')[:3]",
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n23        0.76718       1.00080          0.01378         0.01185   \n21        0.03512       0.00280          0.00380         0.00024   \n22        0.03525       0.00224          0.00380         0.00034   \n\n   param_colsample_bytree param_learning_rate param_n_estimators  \\\n23                0.60000             0.10000                 60   \n21                0.60000             0.10000                 60   \n22                0.60000             0.10000                 60   \n\n   param_num_leaves param_subsample  \\\n23                9         1.00000   \n21                9         0.60000   \n22                9         0.80000   \n\n                                               params  split0_test_score  \\\n23  {'colsample_bytree': 0.6, 'learning_rate': 0.1...            0.95105   \n21  {'colsample_bytree': 0.6, 'learning_rate': 0.1...            0.95105   \n22  {'colsample_bytree': 0.6, 'learning_rate': 0.1...            0.95105   \n\n    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n23            0.97887            0.98592            0.97887          0.97368   \n21            0.97887            0.98592            0.97887          0.97368   \n22            0.97887            0.98592            0.97887          0.97368   \n\n    std_test_score  rank_test_score  \n23         0.01338                1  \n21         0.01338                1  \n22         0.01338                1  ",
      "text/html": "\n  <div id=\"df-3c98b696-ad3a-46cc-845f-613755bcd162\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_colsample_bytree</th>\n      <th>param_learning_rate</th>\n      <th>param_n_estimators</th>\n      <th>param_num_leaves</th>\n      <th>param_subsample</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>0.76718</td>\n      <td>1.00080</td>\n      <td>0.01378</td>\n      <td>0.01185</td>\n      <td>0.60000</td>\n      <td>0.10000</td>\n      <td>60</td>\n      <td>9</td>\n      <td>1.00000</td>\n      <td>{'colsample_bytree': 0.6, 'learning_rate': 0.1...</td>\n      <td>0.95105</td>\n      <td>0.97887</td>\n      <td>0.98592</td>\n      <td>0.97887</td>\n      <td>0.97368</td>\n      <td>0.01338</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.03512</td>\n      <td>0.00280</td>\n      <td>0.00380</td>\n      <td>0.00024</td>\n      <td>0.60000</td>\n      <td>0.10000</td>\n      <td>60</td>\n      <td>9</td>\n      <td>0.60000</td>\n      <td>{'colsample_bytree': 0.6, 'learning_rate': 0.1...</td>\n      <td>0.95105</td>\n      <td>0.97887</td>\n      <td>0.98592</td>\n      <td>0.97887</td>\n      <td>0.97368</td>\n      <td>0.01338</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.03525</td>\n      <td>0.00224</td>\n      <td>0.00380</td>\n      <td>0.00034</td>\n      <td>0.60000</td>\n      <td>0.10000</td>\n      <td>60</td>\n      <td>9</td>\n      <td>0.80000</td>\n      <td>{'colsample_bytree': 0.6, 'learning_rate': 0.1...</td>\n      <td>0.95105</td>\n      <td>0.97887</td>\n      <td>0.98592</td>\n      <td>0.97887</td>\n      <td>0.97368</td>\n      <td>0.01338</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c98b696-ad3a-46cc-845f-613755bcd162')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n        \n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\">\n    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n  </svg>\n      </button>\n      \n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n      <script>\n        const buttonEl =\n          document.querySelector('#df-3c98b696-ad3a-46cc-845f-613755bcd162 button.colab-df-convert');\n        buttonEl.style.display =\n          google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n        async function convertToInteractive(key) {\n          const element = document.querySelector('#df-3c98b696-ad3a-46cc-845f-613755bcd162');\n          const dataTable =\n            await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                     [key], {});\n          if (!dataTable) return;\n\n          const docLinkHtml = 'Like what you see? Visit the ' +\n            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n            + ' to learn more about interactive tables.';\n          element.innerHTML = '';\n          dataTable['output_type'] = 'display_data';\n          await google.colab.output.renderOutput(dataTable, element);\n          const docLink = document.createElement('div');\n          docLink.innerHTML = docLinkHtml;\n          element.appendChild(docLink);\n        }\n      </script>\n    </div>\n  </div>\n  "
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSfMK6guU_V_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666174,
     "user_tz": -540,
     "elapsed": 15,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "7dbd0db1-2cd8-467c-ec70-333a9f834d2f"
   },
   "source": "# 最高性能のモデルを取得\nbest = gscv.best_estimator_\nbest",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LGBMClassifier(colsample_bytree=0.6, n_estimators=60, num_leaves=9,\n               random_state=0, subsample=0.6)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DGXPFGVVnRh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666175,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "87cd655e-5a5e-4d09-ce6d-8229a93e0f67"
   },
   "source": "# 参考に全データを用いて精度（正解率）を確認してみる\nbest.score(x, y)",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# classification_reportを確認してみる\nprediction = best.predict(x)\nprint(classification_report(y, prediction))",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnCogf-f0HhB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666175,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "4eefd756-a68a-42d2-bd27-549a604555cc"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       212\n           1       1.00      1.00      1.00       357\n\n    accuracy                           1.00       569\n   macro avg       1.00      1.00      1.00       569\nweighted avg       1.00      1.00      1.00       569\n\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3a04hJZqDzO"
   },
   "source": "## 特徴量（説明変数）の重要度を確認する"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "ivb_uClbqWkw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666175,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "e20b4361-8c8c-4cff-f6b2-572705dadfa5"
   },
   "source": "# 特徴量重要度\nimportances= best.feature_importances_\ndf_importances =pd.DataFrame(data=importances, index=train_x.columns)\ndf_importances.sort_values(0, ascending=False)",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                          0\nworst perimeter          44\nworst texture            44\nworst area               38\nworst concave points     36\nmean texture             36\nmean concave points      26\nworst smoothness         24\narea error               24\nworst concavity          21\nworst symmetry           19\nworst radius             15\nsmoothness error         14\nradius error             12\ncompactness error        11\nworst fractal dimension  10\nmean concavity           10\nfractal dimension error   9\nmean symmetry             9\nworst compactness         9\nmean smoothness           9\nsymmetry error            8\nmean area                 8\nperimeter error           7\nconcave points error      7\nmean fractal dimension    7\ntexture error             6\nconcavity error           5\nmean compactness          5\nmean radius               5\nmean perimeter            2",
      "text/html": "\n  <div id=\"df-18c8193e-719c-4e7c-87a5-be86b15ee460\">\n    <div class=\"colab-df-container\">\n      <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>worst perimeter</th>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>worst texture</th>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>worst area</th>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>worst concave points</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>mean texture</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>mean concave points</th>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>worst smoothness</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>area error</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>worst concavity</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>worst symmetry</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>worst radius</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>smoothness error</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>radius error</th>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>compactness error</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>worst fractal dimension</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>mean concavity</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>fractal dimension error</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>mean symmetry</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>worst compactness</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>mean smoothness</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>symmetry error</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>mean area</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>perimeter error</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>concave points error</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>mean fractal dimension</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>texture error</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>concavity error</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>mean compactness</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>mean radius</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>mean perimeter</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18c8193e-719c-4e7c-87a5-be86b15ee460')\"\n              title=\"Convert this dataframe to an interactive table.\"\n              style=\"display:none;\">\n        \n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\">\n    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n  </svg>\n      </button>\n      \n  <style>\n    .colab-df-container {\n      display:flex;\n      flex-wrap:wrap;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n      <script>\n        const buttonEl =\n          document.querySelector('#df-18c8193e-719c-4e7c-87a5-be86b15ee460 button.colab-df-convert');\n        buttonEl.style.display =\n          google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n        async function convertToInteractive(key) {\n          const element = document.querySelector('#df-18c8193e-719c-4e7c-87a5-be86b15ee460');\n          const dataTable =\n            await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                     [key], {});\n          if (!dataTable) return;\n\n          const docLinkHtml = 'Like what you see? Visit the ' +\n            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n            + ' to learn more about interactive tables.';\n          element.innerHTML = '';\n          dataTable['output_type'] = 'display_data';\n          await google.colab.output.renderOutput(dataTable, element);\n          const docLink = document.createElement('div');\n          docLink.innerHTML = docLinkHtml;\n          element.appendChild(docLink);\n        }\n      </script>\n    </div>\n  </div>\n  "
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# （参考）matplotlibで画像サイズの調整（横幅、縦幅）\nplt.figure(figsize=(10,12))\nn_features = train_x.shape[1] # 特徴量の数\nplt.barh(range(n_features), best.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), train_x.columns)\nplt.plot;",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "M5h5bcrm0ACg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670295666773,
     "user_tz": -540,
     "elapsed": 604,
     "user": {
      "displayName": "廣岡雅人",
      "userId": "09611567210500329356"
     }
    },
    "outputId": "841e90a1-3c9d-4778-b02a-235fdf58bbec"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x864 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}