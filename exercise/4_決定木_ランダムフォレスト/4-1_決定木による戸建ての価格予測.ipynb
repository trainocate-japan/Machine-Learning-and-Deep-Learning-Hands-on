{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ac47a8",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trainocate-japan/Machine-Learning-and-Deep-Learning-Hands-on/blob/main/exercise/4_決定木_ランダムフォレスト/4-1_決定木による戸建ての価格予測.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWQGngD4wPuN"
   },
   "source": [
    "# 4-1_決定木による戸建ての価格予測\n",
    "このノートブックでは、決定木で回帰の予測モデルを作成します。\n",
    "\n",
    "予測を行うテーマは線形回帰の演習で予測をした戸建て物件の価格を予測することです。\n",
    "\n",
    "決定木は回帰にも分類にも用いることができ、用途に応じて以下の二つのモデルを使い分けます。\n",
    "- 回帰：sklearn.tree.DecisionTreeRegressor\n",
    "- 分類：sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "[決定木のAPIドキュメント](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJetzahcwPuS"
   },
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvNMKExDwPuU"
   },
   "outputs": [],
   "source": [
    "# データを処理するための基本的なライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNANHSRZvUGD"
   },
   "outputs": [],
   "source": [
    "# 決定木モデルをインポート\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# 決定木を可視化したい場合はplot_treeもインポートする\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Tzae4NmeK-V"
   },
   "outputs": [],
   "source": [
    "# matplotlibで日本語表示するための設定\n",
    "!pip install japanize_matplotlib\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62uPlYFxwPuV"
   },
   "source": [
    "## データの準備\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQDqP9jozH8L"
   },
   "source": [
    "#### データを取り込む\n",
    "- pandasのread_csvメソッドを使用して、mlho/data/totsuka_kodate.csvファイルを読み込みます\n",
    "- 読み込んだものは変数totsuka_kodateに代入します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvZ6cDQrwPuW"
   },
   "outputs": [],
   "source": [
    "totsuka_kodate = pd.read_csv(\"totsuka_kodate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJ-bNCyhzi-c"
   },
   "source": [
    "#### データを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wy3z5obPwPuc"
   },
   "outputs": [],
   "source": [
    "# 読み込んだデータを確認（すでに確認済みのデータなのでheadのみ）\n",
    "#totsuka_kodate = totsuka_kodate[1:]\n",
    "totsuka_kodate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDbJ35IiwPuc"
   },
   "source": [
    "#### 説明変数、目的変数を切り出す\n",
    "- 説明変数は「'築年数','最寄駅距離（分）','延床面積（㎡）','面積（㎡）','前面道路幅員（ｍ）','地区名', '前面道路種類', '土地の形状'」をダミー変数化して選択\n",
    "- 目的変数は「'取引価格'」を選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d8LINkRwPud"
   },
   "outputs": [],
   "source": [
    "x = pd.get_dummies( totsuka_kodate[['ごみのリサイクル率']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeJ0HULaDiWg"
   },
   "outputs": [],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HmktW21zrMu"
   },
   "outputs": [],
   "source": [
    "y = totsuka_kodate['出生数']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThA6j4gxiAqf"
   },
   "outputs": [],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E_YN835Ogsi"
   },
   "source": [
    "#### データを訓練データとテストデータに分割する\n",
    "**本研修でtotsuka_kodateデータセットを使用する際には、訓練データ70%、random_state=8で固定しています。他のモデルとの比較をしやすくするためです**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bUAt_kXEGHP"
   },
   "outputs": [],
   "source": [
    "# 訓練データと検証データに分割(70%を訓練用に使用)\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4aFypH-vzjn"
   },
   "source": [
    "決定木系のモデルではスケールを調整する必要は基本的にありません。決定木は値の大小だけで判断を行うためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g060NJBVwPug"
   },
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dHpIxaz0F64"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJJoZ1Qu0B-4"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5odUJKw3wPuh"
   },
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5LEIOyCCsnq"
   },
   "source": [
    "## 作成された決定木を可視化する\n",
    "学習したモデルで精度を評価する前に学習により作成された、決定木を可視化してみます。<br>\n",
    "木を可視化することで何が重要な説明変数だったのかのヒントを得ることができるかもしれません。\n",
    "\n",
    "可視化をする方法はいくつかありますが、今回はscikit-learnのplot_treeメソッドを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HnMBei394SR"
   },
   "outputs": [],
   "source": [
    "# 決定木の可視化を行う\n",
    "# matplotlibで画像サイズの調整（横幅、縦幅）\n",
    "plt.figure(figsize=(45,10))\n",
    "# 描画と設定\n",
    "plot_tree(\n",
    "    model, # 可視化するモデルを指定\n",
    "    max_depth=6, # 可視化する木の深さ\n",
    "    feature_names = train_x.columns, # 分割するときの説明変数名を設定\n",
    "    filled=True, # 色を付ける場合はTrue\n",
    "    fontsize=12,\n",
    "    impurity=False # ジニ不純度(どれくらい分類できていないかどうか)を表示するかどうか\n",
    "    )\n",
    "#matplotlibで保存\n",
    "#plt.savefig(\"tree.pdf\")\n",
    "plt.show()  # 結果を表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb1hamj3JCpR"
   },
   "source": [
    "多くの分岐があり、一見すると何が大事なのかわかりにくいですが、特に多くのサンプルを分割できている条件は重要な特徴量（説明変数）である可能性があります。<br>\n",
    "これはなぜその物件が高いのか安いのかということを理由付ける条件を推察することに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0duJDsKK0eD"
   },
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQTvyY-7OEUs"
   },
   "outputs": [],
   "source": [
    "# 訓練データで精度を確認してみる\n",
    "model.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV3vYGHoO92d"
   },
   "outputs": [],
   "source": [
    "# 検証データで精度を確認してみる\n",
    "model.score(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAWdf6Jlzr1S"
   },
   "outputs": [],
   "source": [
    "# 訓練データで予測し、そのうち最初の5件だけを表示する\n",
    "model.predict(train_x)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO0fspmN7I2z"
   },
   "outputs": [],
   "source": [
    "# 正解を確認してみる\n",
    "train_y.values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jIGSlR0Pu0w"
   },
   "outputs": [],
   "source": [
    "# 検証データで予測し、最初の5件だけを表示する\n",
    "model.predict(val_x)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUadSyCS7O2k"
   },
   "outputs": [],
   "source": [
    "# 正解を確認してみる\n",
    "val_y.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ0pTLdw6FfL"
   },
   "source": [
    "決定木は、予測を説明しやすいことが大きな長所ですが、デフォルトの設定ではトレーニングデータに完全に適合するまで木を作り続けてしまうため、訓練データの特徴に過剰に適合し汎用性がない状態になってしまう過学習を起こしやすい欠点があります。\n",
    "\n",
    "次は、決定木の過学習を緩和させるためにハイパーパラメータを調整してみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVAYbI170TH5"
   },
   "source": [
    "# 決定木モデルのパラメータチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "206EI4OX0eig"
   },
   "source": [
    "決定木の過学習を抑制するために、モデルを学習する際の詳細設定を行うハイパーパラメータを調整します。\n",
    "\n",
    "決定木のハイパーパラメータのうち特に重要なハイパーパラメータは以下の3つです\n",
    "- **max_depth:**決定木の最大の深さ\n",
    "- **min_sample_leaf:**葉ノード（木の先端）に分類される最小のサンプル数。この数を下回らないようになる。\n",
    "- **max_leaf_nodes:**葉ノードの総数\n",
    "\n",
    "主には上のハイパーパラメータのうち1つか2つを調整するケースが多いです。そのほかのハイパーパラメータについては以下の公式リファレンスに記載があります。<br>\n",
    "[決定木のAPIリファレンス](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuWowQ7p0eio"
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータを変えて、精度の変化を確認してみましょう\n",
    "# 今回はmax_depthを変更してみます\n",
    "model = DecisionTreeRegressor(max_depth = 20, random_state=0)\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AknN-IVF0eio"
   },
   "outputs": [],
   "source": [
    "# 訓練データで精度を確認してみる\n",
    "model.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLb1eXg30eip"
   },
   "outputs": [],
   "source": [
    "# 検証データで精度を確認してみる\n",
    "model.score(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU9aJQEFHrah"
   },
   "outputs": [],
   "source": [
    "# 訓練データで予測し、そのうち最初の5件だけを表示する\n",
    "model.predict(train_x)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I606wBrbHraw"
   },
   "outputs": [],
   "source": [
    "# 正解を確認してみる\n",
    "train_y.values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhp6dR-IHrax"
   },
   "outputs": [],
   "source": [
    "# 検証データで予測し、最初の5件だけを表示する\n",
    "model.predict(val_x)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QSPA1ZyHrax"
   },
   "outputs": [],
   "source": [
    "# 正解を確認してみる\n",
    "val_y.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhvTvlKPPO1M"
   },
   "source": [
    "**※ 調整例**\n",
    "\n",
    "`model = DecisionTreeRegressor(max_depth=5, random_state=0)`\n",
    "\n",
    "過学習を抑制して43%程の精度が出ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3a04hJZqDzO"
   },
   "source": [
    "## 特徴量（説明変数）の重要度を確認する\n",
    "決定木は木の作成に使われた特徴量（説明変数）のうち重要なものが何であったかを定量的に出力することもできます。<br>\n",
    "需要な特徴量を把握することは実務上でも役立ちますし、他のモデルを用いるときにどの特徴量を使うのが有効なのかを判断することにも役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lANr62Q2qIrB"
   },
   "outputs": [],
   "source": [
    "# 特徴量重要度\n",
    "importances= model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seiQMM8_IclR"
   },
   "outputs": [],
   "source": [
    "# DataFrameに整形して出力\n",
    "# dataを特徴量重要度に設定し、行のインデックスを説明変数の列名にする\n",
    "df_importances =pd.DataFrame(data=importances, index=train_x.columns)\n",
    "df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7j9Z8vKLLkQt"
   },
   "outputs": [],
   "source": [
    "# 特徴量重要度（0番目の列）でソートする。ascending=Falseで降順に並び替える\n",
    "df_importances.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivb_uClbqWkw"
   },
   "outputs": [],
   "source": [
    "# （参考）matplotlibで棒グラフにする\n",
    "plt.figure(figsize=(10,12))   # グラフのサイズ\n",
    "n_features = train_x.shape[1] # 特徴量の数\n",
    "plt.barh(range(n_features), model.feature_importances_, align='center') # x軸に特徴量、y軸に重要度を表示して中央寄せ（横棒グラフなので、x,yが逆）\n",
    "plt.yticks(np.arange(n_features), train_x.columns) # x軸に項目名を表示\n",
    "plt.plot;                     # グラフを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN3gz9z0UWit"
   },
   "source": [
    "完全に0の特徴量もありますが、これは一度も木の作成に用いられなかった特徴量です。これらは全く役に立たないわけではなく、今回は木の作成に採用されなかっただけだということにも注意してください。<br>\n",
    "のちに出てくるランダムフォレストや勾配ブースティング木の方がより偏りなく見ることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMKeLKrQrQtX"
   },
   "source": [
    "このノートブックは以上です。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6Jf4ECh65aMjhjqvo1Vi1",
   "collapsed_sections": [],
   "mount_file_id": "1ttG3w-XELSofeMynpIzwBXZpeZO_Ta2o",
   "name": "4-1_決定木による戸建ての価格予測.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
