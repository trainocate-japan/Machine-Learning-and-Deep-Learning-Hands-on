{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1OVfBFwY2Ay-3jlS8PaRjtxUtQQ0llYLG",
   "authorship_tag": "ABX9TyP8qmKvzOwXKesPy4VBebd1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "id": "f33db5b5",
   "cell_type": "markdown",
   "source": "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trainocate-japan/Machine-Learning-and-Deep-Learning-Hands-on/blob/main/exercise/7_CNNによる画像分類/7-1_TensorFlow_Kerasによる画像分類.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBD6qPwaM-mc"
   },
   "source": "# 7-1_TensorFlow/Kerasによる画像分類\nこのノートブックではTensorFlow / Keras を用いて画像分類を行うモデルを作成します。<br>\nテーマはMNISTという手書きの数字を0～9のどれなのか判別するものです。\n\n画像データを分類する場合には、画像を同じサイズに準備したり、ラベル付けの作業を事前に行っておく必要がありますが、今回はデータセットとしてすでに用意してあります。また、これまでの構造化データとは違い、説明変数は画像の各ピクセルのみです。データの範囲や説明変数の数はすでに分かっているので、データについて詳細に確認する作業は省略し、必要な作業に絞ってプログラミングしていきます。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBDR3CvxewJw"
   },
   "source": "## ランタイムをGPUに切り替える\n画像分類では非常に多くのコンピューティングリソースを使うため、CPUではとても時間がかかってしまいます。\nそこで、Google ColaboratoryのランタイムをGPUに切り替えます。\n\nランタイムをGPUに切り替えるには、上部のメニューから「ランタイム > ランタイムのタイプを変更」を選択し、ハードウェアアクセラレーターでGPUを選択して、保存をクリックします。\n\nKerasの場合は自動的にランタイムを判断して、GPUが使用できる場合にはGPUを使用して演算を行います。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJO3PPzqsq8d"
   },
   "source": "## ライブラリのインポート"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gB5UUoAXIVmC"
   },
   "source": "import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Keras / TensorFlow関連のライブラリ\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.datasets import mnist",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz2h7_8St1wi"
   },
   "source": "## MNISTのダウンロードおよびデータの準備\nKerasのデータセットを使ってMNISTのデータをダウンロードします。\n\nMNISTは0から9までの手書き数字画像データ7万件です。\n\n訓練データ6万件と検証データ1万件に最初から分けてあるので、それぞれ変数に格納します。\n\n"
  },
  {
   "cell_type": "code",
   "source": "# MNISTをロードする\n(train_images, train_labels), (val_images, val_labels) = mnist.load_data()",
   "metadata": {
    "id": "wghgrdFwYbq2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 訓練データの件数\nlen(train_images)",
   "metadata": {
    "id": "ZBaIvMfHYb0d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 検証データの件数\nlen(val_images)",
   "metadata": {
    "id": "11MriyDWYk9V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "変数に格納したデータは60000×28×28のnumpy配列として格納されています。<br>\nこれを255で割ることにより、一つ一つのピクセル情報を0～1の範囲に正規化します。<br>\n画像の場合は必ず0～255の範囲に収まるため単純に割り算を行うことで正規化できます。",
   "metadata": {
    "id": "SFfEBWyXYyRQ"
   }
  },
  {
   "cell_type": "code",
   "source": "# ロード直後のデータの形状を確認する\ntrain_images.shape",
   "metadata": {
    "id": "9lY0u3cAYp_t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 一件目のデータを確認する\ntrain_images[0]",
   "metadata": {
    "id": "TQ697aITl-Ik"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 訓練データをfloat型に直し、255で割って正規化\ntrain_images = train_images.astype(\"float32\") / 255.",
   "metadata": {
    "id": "WQdkziV8aHOn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 変換後のデータを確認する\ntrain_images[0]",
   "metadata": {
    "id": "_ezzH9mBaMyt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 検証データも正規化\nval_images = val_images.astype(\"float32\") / 255.",
   "metadata": {
    "id": "waDXtCEOfQ9U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 目的変数である、0～9のどれに当たるかのラベルをone-hot表現に直します。\n# 変換はKerasのユーティリティ機能を使用します。\ntrain_labels = tf.keras.utils.to_categorical(train_labels, 10)\nval_labels = tf.keras.utils.to_categorical(val_labels, 10)",
   "metadata": {
    "id": "OyjYmYmAfsS7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 変換後の目的変数の先頭10件を確認する\ntrain_labels[:10]",
   "metadata": {
    "id": "_6shGFqkf-J3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8PD3u0Rb6EPg"
   },
   "source": "# (参考)ダウンロードしたイメージを表示してみる\nfig = plt.figure(figsize=(10, 4)) # 図のサイズを指定する\ncount = 0\nfor (image, label) in zip(train_images, train_labels): # ひとつづつイメージとラベルを取り込みながら繰り返す\n    subplot = fig.add_subplot(3, 10, count + 1) # 3行10列の領域に区切り、一つ目から順番に画像を当てはめていく\n    subplot.set_title(np.argmax(label)) # 正解ラベルを設定\n    subplot.set_xticks([]) # x軸目盛を非表示\n    subplot.set_yticks([]) # y軸目盛を非表示\n    subplot.imshow(image.reshape((28, 28)),\n                   vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\n    count = count + 1\n    if count >= 30: # 30個の画像を表示したら終了する\n      break\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdQ0Tp2IvFy8"
   },
   "source": "## モデルの定義\n- モデルの概要\n  - 畳み込み層(16チャネル)\n    - 畳み込みカーネル 5×5\n    - パディングにより畳み込み後にサイズを小さくしない\n    - 活性化関数はReLUを使用（カーネル通過後の特徴をより際立たせる）\n  -プーリング層(16チャネル)\n    - マックスプーリング 2×2\n  - 全結合層(1024)\n  - 出力層(10)\n\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tpL_niBTXggS"
   },
   "source": "# GPUを使用する場合は乱数シードを固定しても、学習の過程で結果が少し異なる場合があります。\ntf.random.set_seed(0)\n\nmodel = Sequential()\n\n# 畳み込み層\nmodel.add(Conv2D(16, (5, 5), padding='same', input_shape=(28,28,1)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n# プーリング層\nmodel.add(MaxPooling2D((2, 2)))\n# 全結合層\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n# 出力層\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\n# 最適化手法としてAdam、誤差関数として交差エントロピー誤差を設定\n# metricsは損失以外に実行中に確認する評価指標を指定できる。\noptimizer = optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n\n# モデルの形状を確認\nmodel.summary()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knfetV1MiKQ-"
   },
   "source": "## 学習"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LlQCTsKKXkr5"
   },
   "source": "history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), batch_size=256, epochs=10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5R1JCmtflv"
   },
   "source": "## 評価"
  },
  {
   "cell_type": "code",
   "source": "# 損失、正解率を可視化する\ndf_history = pd.DataFrame(history.history)\ndf_history.plot(figsize=(10, 6))",
   "metadata": {
    "id": "WPKy4-ArgUHs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# （参考）グラフを整形する\n# 損失\npd.DataFrame({'loss': history.history['loss'], \n           'val_loss': history.history['val_loss']}).plot(figsize=(15, 8))",
   "metadata": {
    "id": "4Ta7PLabiEXw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8xZbQ1j1k9Z"
   },
   "source": "# （参考）グラフを整形する\n# 正解率\npd.DataFrame({'acc': history.history['acc'], \n           'val_acc': history.history['val_acc']}).plot(figsize=(15, 8))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xxa5mLkxonQ"
   },
   "source": "## 予測を試してみる"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XDM-yO8AYMZY"
   },
   "source": "# n番目のデータに対して予測を行う\nn = 0\n\nimage = val_images[n]\nlabel = val_labels[n]\n\np_val = model.predict(np.array([image]))           # 一つの画像の予測確率\nprediction = np.argmax(p_val[0])                   # 予測確率が最大のものを取得\ncorrect = np.argmax(label)                         # 正解ラベルも予測確率が最大のものを取得\nplt.title(f'pred:{prediction} / corr:{correct}')   # ラベルを設定\nplt.imshow(image.reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeaktA3c4Jev"
   },
   "source": "（参考）間違いだったデータを確認してみる"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bhmrebru4BXm"
   },
   "source": "# 間違いだったデータを確認してみる\nfig = plt.figure(figsize=(10, 5)) # 図のサイズを指定する\ncount = 0\nfor (image, label) in zip(val_images, val_labels): # ひとつづつイメージとラベルを取り込みながら繰り返す\n  p_val = model.predict(np.array([image]))\n  prediction = np.argmax(p_val[0])\n  correct = np.argmax(label)\n  if prediction == correct:\n    continue      \n  subplot = fig.add_subplot(3, 5, count + 1) # 3行10列の領域に区切り、一つ目から順番に画像を当てはめていく\n  subplot.set_title(f'pred:{prediction} / corr:{correct}') # ラベルを設定\n  subplot.set_xticks([]) # x軸目盛を非表示\n  subplot.set_yticks([]) # y軸目盛を非表示\n  subplot.imshow(image.reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\n  count = count + 1\n  if count >= 15: # 15個の画像を表示したら終了する\n    break\nplt.show()",
   "execution_count": null,
   "outputs": []
  }
 ]
}