{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1OVfBFwY2Ay-3jlS8PaRjtxUtQQ0llYLG",
   "authorship_tag": "ABX9TyNBUW6zkd6ySUipq23F7qdb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "id": "430289cf",
   "cell_type": "markdown",
   "source": "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trainocate-japan/Machine-Learning-and-Deep-Learning-Hands-on/blob/main/exercise/7_CNNによる画像分類/7-3_（演習）TensorFlow_Kerasによる服の画像分類.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBD6qPwaM-mc"
   },
   "source": "# 7-3_（演習）TensorFlow/Kerasによる服の画像分類\nこのノートブックではTensorFlow / Keras を用いて画像分類を行うモデルを作成します。<br>\nテーマはFashion-MNISTという服の種別を判別するものです。\n\nMNISTと画像のサイズやデータ量などが同じなので、MNISTで試した手法を同じように用いることができますが、判別するものが手書き文字から服に代わっているため、分類の難易度が上がっています。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBDR3CvxewJw"
   },
   "source": "## ランタイムをGPUに切り替える\n画像分類では非常に多くのコンピューティングリソースを使うため、CPUではとても時間がかかってしまいます。\nそこで、Google ColaboratoryのランタイムをGPUに切り替えます。\n\nランタイムをGPUに切り替えるには、上部のメニューから「ランタイム > ランタイムのタイプを変更」を選択し、ハードウェアアクセラレーターでGPUを選択して、保存をクリックします。\n\nPyTorchでは、別途GPUを使うためのプログラミングが必要ですが、Kerasの場合は自動的にランタイムを判断して、GPUが使用できる場合にはGPUを使用して演算を行います。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJO3PPzqsq8d"
   },
   "source": "## ライブラリのインポート"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gB5UUoAXIVmC"
   },
   "source": "import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Keras / TensorFlow関連のライブラリ\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.datasets import fashion_mnist",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz2h7_8St1wi"
   },
   "source": "## Fashion-MNISTのダウンロードおよびデータの準備\nKerasのデータセットを使ってFashion-MNISTのデータをダウンロードします。\n\nFasion-MNISTは服の種類を0から9までのカテゴリクラスでラベル付けしている画像データ7万件です。それぞれのクラスとラベルの紐づけは以下のようになっています。\n\n|Label|\tDescription|\n|----|----|\n|0|\tT-shirt/top|\n|1|\tTrouser|\n|2|\tPullover|\n|3|\tDress|\n|4|\tCoat|\n|5|\tSandal|\n|6|\tShirt|\n|7|\tSneaker|\n|8|\tBag|\n|9|\tAnkle boot|\n\n訓練データ6万件と検証データ1万件に最初から分けてあるので、それぞれ変数に格納します。\n\n\n"
  },
  {
   "cell_type": "code",
   "source": "# Fashion-MNISTをロードする\n(train_images, train_labels), (val_images, val_labels) = fashion_mnist.load_data()",
   "metadata": {
    "id": "wghgrdFwYbq2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 訓練データの件数\nlen(train_images)",
   "metadata": {
    "id": "ZBaIvMfHYb0d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 検証データの件数\nlen(val_images)",
   "metadata": {
    "id": "11MriyDWYk9V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "変数に格納したデータは60000×28×28のnumpy配列として格納されています。<br>\nこれを255で割ることにより、一つ一つのピクセル情報を0～1の範囲に正規化します。<br>\n画像の場合は必ず0～255の範囲に収まるため単純に割り算を行うことで正規化できます。",
   "metadata": {
    "id": "SFfEBWyXYyRQ"
   }
  },
  {
   "cell_type": "code",
   "source": "# ロード直後のデータの形状を確認する\ntrain_images.shape",
   "metadata": {
    "id": "9lY0u3cAYp_t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 一件目のデータを確認する\ntrain_images[0]",
   "metadata": {
    "id": "00oiFC6_oQPe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 訓練データをfloat型に直し、255で割って正規化\ntrain_images = train_images.astype(\"float32\") / 255.",
   "metadata": {
    "id": "WQdkziV8aHOn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 変換後のデータを確認する\ntrain_images[0]",
   "metadata": {
    "id": "_ezzH9mBaMyt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 検証データも正規化\nval_images = val_images.astype(\"float32\") / 255.",
   "metadata": {
    "id": "waDXtCEOfQ9U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 目的変数である、0～9のどれに当たるかのラベルをone-hot表現に直します。\n# 変換はKerasのユーティリティ機能を使用します。\ntrain_labels = tf.keras.utils.to_categorical(train_labels, 10)\nval_labels = tf.keras.utils.to_categorical(val_labels, 10)",
   "metadata": {
    "id": "OyjYmYmAfsS7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 変換後の目的変数の先頭10件を確認する\ntrain_labels[:10]",
   "metadata": {
    "id": "_6shGFqkf-J3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8PD3u0Rb6EPg"
   },
   "source": "# (参考)ダウンロードしたイメージを表示してみる\nfig = plt.figure(figsize=(10, 4)) # 図のサイズを指定する\ncount = 0\nfor (image, label) in zip(train_images, train_labels): # ひとつづつイメージとラベルを取り込みながら繰り返す\n    subplot = fig.add_subplot(3, 10, count + 1) # 1行10列の領域に区切り、一つ目から順番に画像を当てはめていく\n    subplot.set_title(np.argmax(label)) # 正解ラベルを設定\n    subplot.set_xticks([]) # x軸目盛を非表示\n    subplot.set_yticks([]) # y軸目盛を非表示\n    subplot.imshow(image.reshape((28, 28)),\n                   vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\n    count = count + 1\n    if count >= 30: # 30個の画像を表示したら終了する\n      break\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdQ0Tp2IvFy8"
   },
   "source": "## モデルの定義\nfasion-MNISTではMNISTより層数を増やすなどの工夫が必要です。\n\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tpL_niBTXggS"
   },
   "source": "# GPUを使用する場合は乱数シードを固定しても、学習の過程で結果が少し異なる場合があります。\ntf.random.set_seed(0)\n\nmodel = Sequential()\n\n# ★★ここに畳み込み層、プーリング層、全結合層、出力層を定義してください\n\n\n\n\n# 最適化手法としてAdam、誤差関数として交差エントロピー誤差を設定\n# metricsは損失以外に実行中に確認する評価指標を指定できる。\n#★optimizer = optimizers.Adam(learning_rate=0.001)\n#★model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n\n# モデルの形状を確認\nmodel.summary()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knfetV1MiKQ-"
   },
   "source": "## 学習"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LlQCTsKKXkr5"
   },
   "source": "# ★★定義したモデルで学習を行う（エポック数10、バッチサイズ256、validation_data=(val_images, val_labels)、戻り値は変数historyに格納）\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5R1JCmtflv"
   },
   "source": "## 評価"
  },
  {
   "cell_type": "code",
   "source": "# ★★学習状況を可視化する\n",
   "metadata": {
    "id": "WPKy4-ArgUHs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# （参考）グラフを整形する\n# 損失\npd.DataFrame({'loss': history.history['loss'], \n           'val_loss': history.history['val_loss']}).plot(figsize=(15, 8))",
   "metadata": {
    "id": "4Ta7PLabiEXw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8xZbQ1j1k9Z"
   },
   "source": "# （参考）グラフを整形する\n# 正解率\npd.DataFrame({'acc': history.history['acc'], \n           'val_acc': history.history['val_acc']}).plot(figsize=(15, 8))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xxa5mLkxonQ"
   },
   "source": "## 予測を試してみる"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XDM-yO8AYMZY"
   },
   "source": "# n番目のデータに対して予測を行う\nn = 0\n\nimage = val_images[n]\nlabel = val_labels[n]\n\np_val = model.predict(np.array([image]))           # 一つの画像の予測確率\nprediction = np.argmax(p_val[0])                   # 予測確率が最大のものを取得\ncorrect = np.argmax(label)                         # 正解ラベルも予測確率が最大のものを取得\nplt.title(f'pred:{prediction} / corr:{correct}')   # ラベルを設定\nplt.imshow(image.reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeaktA3c4Jev"
   },
   "source": "（参考）間違いだったデータを確認してみる"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bhmrebru4BXm"
   },
   "source": "# 間違いだったデータを確認してみる\nfig = plt.figure(figsize=(10, 5)) # 図のサイズを指定する\ncount = 0\nfor (image, label) in zip(val_images, val_labels): # ひとつづつイメージとラベルを取り込みながら繰り返す\n  p_val = model.predict(np.array([image]))\n  prediction = np.argmax(p_val[0])\n  correct = np.argmax(label)\n  if prediction == correct:\n    continue      \n  subplot = fig.add_subplot(3, 5, count + 1) # 3行10列の領域に区切り、一つ目から順番に画像を当てはめていく\n  subplot.set_title(f'pred:{prediction} / corr:{correct}') # ラベルを設定\n  subplot.set_xticks([]) # x軸目盛を非表示\n  subplot.set_yticks([]) # y軸目盛を非表示\n  subplot.imshow(image.reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\n  count = count + 1\n  if count >= 15: # 15個の画像を表示したら終了する\n    break\nplt.show()\n# |Label\tDescription||0\tT-shirt/top||1\tTrouser||2\tPullover||3\tDress|\n# |4\tCoat||5\tSandal||6\tShirt||7\tSneaker||8\tBag||9\tAnkle boot|",
   "execution_count": null,
   "outputs": []
  }
 ]
}