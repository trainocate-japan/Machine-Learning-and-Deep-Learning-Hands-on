{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "7-2_PyTorchによる画像分類.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1iJMqvHyu8SoIlBRu3oCMjrGDic283Atw",
   "authorship_tag": "ABX9TyPGLMXcIcD/SU3CTzRUIg98"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "id": "fe8dcd7b",
   "cell_type": "markdown",
   "source": "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trainocate-japan/Machine-Learning-and-Deep-Learning-Hands-on/blob/main/exercise/7_CNNによる画像分類/7-2_PyTorchによる画像分類.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6owCnFmowgq"
   },
   "source": "# 7-2_PyTorchによる画像分類\nこのノートブックではPyTorchを用いて画像分類を行うモデルを作成します。<br>\nテーマはMNISTという手書きの数字を0～9のどれなのかを判別するものです。\n\n画像データを分類する場合には、画像を同じサイズに準備したり、ラベル付けの作業を事前に行っておく必要がありますが、今回はデータセットとしてすでに用意してあります。また、これまでの構造化データとは違い、説明変数は画像の各ピクセルのみです。データの範囲や説明変数の数はすでに分かっているので、データについて詳細に確認する作業は省略し、必要な作業に絞ってプログラミングしていきます。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jk0G6GaYQuO"
   },
   "source": "## ランタイムをGPUに切り替える\n画像分類では非常に多くのコンピューティングリソースを使うため、CPUではとても時間がかかってしまいます。\nそこで、Google ColaboratoryのランタイムをGPUに切り替えます。\n\nランタイムをGPUに切り替えるには、上部のメニューから「ランタイム > ランタイムのタイプを変更」を選択し、ハードウェアアクセラレーターでGPUを選択して、保存をクリックします。\n\nKerasの場合は自動的にランタイムを判断して、GPUが使用できる場合にはGPUを使用して演算を行いますが、PyTorchでは、別途GPUを使うためのプログラミングが必要です。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIIYzb-YgpTK"
   },
   "source": "## ライブラリのインポート"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cphdy974lw-2"
   },
   "source": "# データを処理するための基本的なライブラリ\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# データセット用\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\n# PyTorchで使用\nimport torch",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhr-0eLImM0A"
   },
   "source": "#### GPUチェック"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1KgRxyCfmPZn"
   },
   "source": "# GPUが使用できることを確認する。「cuda」がGPUのことで、これが見つかった場合はcuda:0と表示させる\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OM7zyk2mWzU"
   },
   "source": "## データの準備"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbHsrNrJpf0Z"
   },
   "source": "#### Transformsによるデータの前処理\nPyTorchにはデータ変換を定義することで、datasetにする際に自動でデータ変換を行ってくれるTransforms機能があります。\n\ntorchvisionに含まれるデータセットを使用する場合には、ダウンロードと共にTransformsで変換しつつdatasetにすることができるので大変便利です。\n\n今回はtorchvisionからデータをダウンロードするので、この機能を利用してデータをtorchtensorに変換します。\n\nまた、Transformsを使用してデータのスケールを変更することもできます。今回はすでにデータが0～1の範囲で正規化されているため、この作業は行いません。"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zTzszuy_oMx8"
   },
   "source": "# データ変換用関数 Transforms\ntransform = transforms.Compose([\n    # データのテンソル化\n    transforms.ToTensor(),\n])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b50LLDa7qk0P"
   },
   "source": "# データ取得用関数 Dataset\n\n# 訓練用データセットの定義\ntrain_set = datasets.MNIST(\n    root = './data', # ダウンロード先ディレクトリ名 \n    train = True,\n    download = True,\n    transform = transform)\n\n# 検証データセットの定義\nval_set = datasets.MNIST(\n    root = './data', \n    train = False, \n    download = True, \n    transform = transform)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lUADp1Lsp7A"
   },
   "source": "## モデルの定義\n- モデルの概要\n  - 畳み込み層(16チャネル)\n    - 畳み込みカーネル 5×5\n    - パディングにより畳み込み後にサイズを小さくしない\n    - 活性化関数はReLUを使用（カーネル通過後の特徴をより際立たせる）\n  -プーリング層(16チャネル)\n    - マックスプーリング 2×2\n  - 全結合層(1024)\n  - 出力層(10)\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KIbXomDPs5P-"
   },
   "source": "# 乱数の固定化\ntorch.manual_seed(123)\ntorch.cuda.manual_seed(123) # GPUのための乱数固定\n\n# モデルの定義\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 畳み込み層\n        # 引数は順番に「入力チャネル数」「出力チャネル数」「畳み込みカーネルの一辺のサイズ」\n        # paddingオプションで入力画像の外側に縦横2ピクセルのパディングを行い、畳み込み後も画像サイズを維持する。\n        self.conv = torch.nn.Conv2d(1, 16, 5, padding=(2,2))\n        # 活性化関数ReLU\n        self.relu = torch.nn.ReLU(inplace=True)\n        self.dropout1 = torch.nn.Dropout(0.3)\n        # プーリング層\n        self.maxpool = torch.nn.MaxPool2d((2,2))\n        # 全結合層\n        self.flatten = torch.nn.Flatten()\n        self.linear1 = torch.nn.Linear(3136, 1024)\n        # forward定義時にここにReLUを挟む\n        self.dropout2 = torch.nn.Dropout(0.3)\n        self.linear2 = torch.nn.Linear(1024, 10)\n   \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.dropout1(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.dropout2(x)\n        x = self.linear2(x)\n        return x\n\n# 後で設定するPyTorchのCrossEntropyLossは、softmax関数を内包するような損失関数になっています。\n# そのため、Softmax関数を最後に入れる必要がありません。\n# ただし、確率値を求めたい場合には予測値にsoftmax関数を用いる必要があります。",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFa6TgtalrH3"
   },
   "source": "## 学習"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6R7izz7QsTcx"
   },
   "source": "num_epochs = 10\n\n# データローダーの用意\nbatch_size = 256\ntrain_dataloader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\nval_dataloader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = False)\n\n# モデルをインスタンス化\nnet = Net()\nnet = net.to(device) # ★モデルをGPU側に送る。GPUを使用する場合に必要\noptimizer = torch.optim.Adam(net.parameters(), lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\n\n## 学習に必要な空リストを作成\ntrain_loss_list = []#学習損失\ntrain_accuracy_list = []#学習データ正解率\nval_loss_list = []#評価損失\nval_accuracy_list = []#検証データの正答率\n\nfor epoch in range(num_epochs):\n    \n    #学習の進行状況を表示\n    print('--------')\n    print(\"Epoch: {}/{}\".format(epoch + 1, num_epochs))\n\n    #損失と正解率の初期化\n    train_loss = 0      #学習損失\n    train_accuracy = 0  #学習データの正答数\n    val_loss = 0        #評価損失\n    val_accuracy = 0    #検証データの正答数\n\n    #学習モードに設定\n    net.train()\n\n    #ミニバッチごとにデータをロードして学習\n    for x, y in train_dataloader:\n        \n        # GPUヘ転送\n        x = x.to(device)\n        y = y.to(device)\n\n        preds = net(x)\n        predlabels = torch.max(preds, 1)[1] # 予測ラベル導出\n        loss = criterion(preds, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        #ミニバッチごとの損失と精度を備蓄\n        train_loss += loss.item()\n        train_accuracy += (y == predlabels).sum() / batch_size\n    \n    #ミニバッチの平均の損失と正解率を計算\n    batch_train_loss = train_loss / len(train_dataloader)\n    batch_train_accuracy = train_accuracy / len(train_dataloader)\n\n    #評価モードに設定\n    net.eval()\n    #評価時に自動微分をゼロにする\n    with torch.no_grad():\n        for x, y in val_dataloader:\n\n            # GPUヘ転送\n            x = x.to(device)\n            y = y.to(device)\n\n            #データを入力して予測値を計算\n            preds = net(x)\n            predlabels = torch.max(preds, 1)[1] # 予測ラベル導出\n            #損失を計算\n            loss = criterion(preds, y)\n            #ミニバッチごとの損失と精度を備蓄\n            val_loss += loss.item()\n            val_accuracy += (y == predlabels).sum() / batch_size\n\n    #ミニバッチの平均の損失と正解率を計算\n    batch_val_loss = val_loss / len(val_dataloader)\n    batch_val_accuracy = val_accuracy / len(val_dataloader)\n    #エポックごとに損失と正解率を表示\n    print(\"Train_Loss: {:.4f} Train_Accuracy: {:.4f}\".format(batch_train_loss, batch_train_accuracy))\n    print(\"Val_Loss: {:.4f} Val_Accuracy: {:.4f}\".format(batch_val_loss, batch_val_accuracy))\n    #損失と正解率をリスト化して保存\n    train_loss_list.append(batch_train_loss)\n    #train_accuracy_list.append(batch_train_accuracy)\n    train_accuracy_list.append(batch_train_accuracy.cpu())\n    val_loss_list.append(batch_val_loss)\n    #val_accuracy_list.append(batch_val_accuracy)\n    val_accuracy_list.append(batch_val_accuracy.cpu())",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pCPOKKaYzdO"
   },
   "source": "## 評価"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nLy1NFLsLolB"
   },
   "source": "# 損失関数\nplt.figure(figsize=(15, 8))\nplt.plot(train_loss_list, color='b', label='Train_Loss')\nplt.plot(val_loss_list, color='m', label='val_loss')\nplt.legend()\n\n# 精度\nplt.figure(figsize=(15, 8))\nplt.plot(train_accuracy_list, color='b', label='Train_Accuracy')\nplt.plot(val_accuracy_list, color='m', label='val_accuracy')\nplt.legend()\n\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cczf1ing2CJy"
   },
   "source": "(参考)予測をしてみる"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "azKldWTyweX7"
   },
   "source": "# 検証データn番目の画像で予測してみる\nn = 0\n\n# モデルを評価モードにする\nnet.eval()\n\ny_pred = None\nimages = None\nlabels = None\n\n# 検証用データローダからデータを一つのバッチだけ取り出す\nwith torch.no_grad():\n  for x, y in val_dataloader:\n    images = x\n    labels = y\n    break\n\n# 予測を実行する\nimages = images.to(device)\npred = net(images)\npred =pred.to('cpu').detach().numpy().copy()\nprediction = np.argmax(pred, axis=1)\n\n# 画像をnumpyに直して表示できるようにしておく\nimages = images.to('cpu').detach().numpy().copy()\n\nplt.title(f'pred:{prediction[n]} / coll:{labels[n]}')   # ラベルを設定\nplt.imshow(images[n].reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\nplt.show()",
   "execution_count": null,
   "outputs": []
  }
 ]
}