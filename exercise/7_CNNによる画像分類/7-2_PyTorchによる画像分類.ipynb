{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7-2_PyTorchによる画像分類.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1iJMqvHyu8SoIlBRu3oCMjrGDic283Atw","authorship_tag":"ABX9TyPGLMXcIcD/SU3CTzRUIg98"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H6owCnFmowgq"},"source":["# 7-2_PyTorchによる画像分類\n","このノートブックではPyTorchを用いて画像分類を行うモデルを作成します。<br>\n","テーマはMNISTという手書きの数字を0～9のどれなのかを判別するものです。\n","\n","画像データを分類する場合には、画像を同じサイズに準備したり、ラベル付けの作業を事前に行っておく必要がありますが、今回はデータセットとしてすでに用意してあります。また、これまでの構造化データとは違い、説明変数は画像の各ピクセルのみです。データの範囲や説明変数の数はすでに分かっているので、データについて詳細に確認する作業は省略し、必要な作業に絞ってプログラミングしていきます。"]},{"cell_type":"markdown","metadata":{"id":"2jk0G6GaYQuO"},"source":["## ランタイムをGPUに切り替える\n","画像分類では非常に多くのコンピューティングリソースを使うため、CPUではとても時間がかかってしまいます。\n","そこで、Google ColaboratoryのランタイムをGPUに切り替えます。\n","\n","ランタイムをGPUに切り替えるには、上部のメニューから「ランタイム > ランタイムのタイプを変更」を選択し、ハードウェアアクセラレーターでGPUを選択して、保存をクリックします。\n","\n","Kerasの場合は自動的にランタイムを判断して、GPUが使用できる場合にはGPUを使用して演算を行いますが、PyTorchでは、別途GPUを使うためのプログラミングが必要です。"]},{"cell_type":"markdown","metadata":{"id":"AIIYzb-YgpTK"},"source":["## ライブラリのインポート"]},{"cell_type":"code","metadata":{"id":"cphdy974lw-2"},"source":["# データを処理するための基本的なライブラリ\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","\n","# データセット用\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","# PyTorchで使用\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhr-0eLImM0A"},"source":["#### GPUチェック"]},{"cell_type":"code","metadata":{"id":"1KgRxyCfmPZn"},"source":["# GPUが使用できることを確認する。「cuda」がGPUのことで、これが見つかった場合はcuda:0と表示させる\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0OM7zyk2mWzU"},"source":["## データの準備"]},{"cell_type":"markdown","metadata":{"id":"hbHsrNrJpf0Z"},"source":["#### Transformsによるデータの前処理\n","PyTorchにはデータ変換を定義することで、datasetにする際に自動でデータ変換を行ってくれるTransforms機能があります。\n","\n","torchvisionに含まれるデータセットを使用する場合には、ダウンロードと共にTransformsで変換しつつdatasetにすることができるので大変便利です。\n","\n","今回はtorchvisionからデータをダウンロードするので、この機能を利用してデータをtorchtensorに変換します。\n","\n","また、Transformsを使用してデータのスケールを変更することもできます。今回はすでにデータが0～1の範囲で正規化されているため、この作業は行いません。"]},{"cell_type":"code","metadata":{"id":"zTzszuy_oMx8"},"source":["# データ変換用関数 Transforms\n","transform = transforms.Compose([\n","    # データのテンソル化\n","    transforms.ToTensor(),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b50LLDa7qk0P"},"source":["# データ取得用関数 Dataset\n","\n","# 訓練用データセットの定義\n","train_set = datasets.MNIST(\n","    root = './data', # ダウンロード先ディレクトリ名 \n","    train = True,\n","    download = True,\n","    transform = transform)\n","\n","# 検証データセットの定義\n","val_set = datasets.MNIST(\n","    root = './data', \n","    train = False, \n","    download = True, \n","    transform = transform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4lUADp1Lsp7A"},"source":["## モデルの定義\n","- モデルの概要\n","  - 畳み込み層(16チャネル)\n","    - 畳み込みカーネル 5×5\n","    - パディングにより畳み込み後にサイズを小さくしない\n","    - 活性化関数はReLUを使用（カーネル通過後の特徴をより際立たせる）\n","  -プーリング層(16チャネル)\n","    - マックスプーリング 2×2\n","  - 全結合層(1024)\n","  - 出力層(10)\n"]},{"cell_type":"code","metadata":{"id":"KIbXomDPs5P-"},"source":["# 乱数の固定化\n","torch.manual_seed(123)\n","torch.cuda.manual_seed(123) # GPUのための乱数固定\n","\n","# モデルの定義\n","\n","class Net(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # 畳み込み層\n","        # 引数は順番に「入力チャネル数」「出力チャネル数」「畳み込みカーネルの一辺のサイズ」\n","        # paddingオプションで入力画像の外側に縦横2ピクセルのパディングを行い、畳み込み後も画像サイズを維持する。\n","        self.conv = torch.nn.Conv2d(1, 16, 5, padding=(2,2))\n","        # 活性化関数ReLU\n","        self.relu = torch.nn.ReLU(inplace=True)\n","        self.dropout1 = torch.nn.Dropout(0.3)\n","        # プーリング層\n","        self.maxpool = torch.nn.MaxPool2d((2,2))\n","        # 全結合層\n","        self.flatten = torch.nn.Flatten()\n","        self.linear1 = torch.nn.Linear(3136, 1024)\n","        # forward定義時にここにReLUを挟む\n","        self.dropout2 = torch.nn.Dropout(0.3)\n","        self.linear2 = torch.nn.Linear(1024, 10)\n","   \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        x = self.dropout1(x)\n","        x = self.maxpool(x)\n","        x = self.flatten(x)\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout2(x)\n","        x = self.linear2(x)\n","        return x\n","\n","# 後で設定するPyTorchのCrossEntropyLossは、softmax関数を内包するような損失関数になっています。\n","# そのため、Softmax関数を最後に入れる必要がありません。\n","# ただし、確率値を求めたい場合には予測値にsoftmax関数を用いる必要があります。"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFa6TgtalrH3"},"source":["## 学習"]},{"cell_type":"code","metadata":{"id":"6R7izz7QsTcx"},"source":["num_epochs = 10\n","\n","# データローダーの用意\n","batch_size = 256\n","train_dataloader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n","val_dataloader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = False)\n","\n","# モデルをインスタンス化\n","net = Net()\n","net = net.to(device) # ★モデルをGPU側に送る。GPUを使用する場合に必要\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","## 学習に必要な空リストを作成\n","train_loss_list = []#学習損失\n","train_accuracy_list = []#学習データ正解率\n","val_loss_list = []#評価損失\n","val_accuracy_list = []#検証データの正答率\n","\n","for epoch in range(num_epochs):\n","    \n","    #学習の進行状況を表示\n","    print('--------')\n","    print(\"Epoch: {}/{}\".format(epoch + 1, num_epochs))\n","\n","    #損失と正解率の初期化\n","    train_loss = 0      #学習損失\n","    train_accuracy = 0  #学習データの正答数\n","    val_loss = 0        #評価損失\n","    val_accuracy = 0    #検証データの正答数\n","\n","    #学習モードに設定\n","    net.train()\n","\n","    #ミニバッチごとにデータをロードして学習\n","    for x, y in train_dataloader:\n","        \n","        # GPUヘ転送\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        preds = net(x)\n","        predlabels = torch.max(preds, 1)[1] # 予測ラベル導出\n","        loss = criterion(preds, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #ミニバッチごとの損失と精度を備蓄\n","        train_loss += loss.item()\n","        train_accuracy += (y == predlabels).sum() / batch_size\n","    \n","    #ミニバッチの平均の損失と正解率を計算\n","    batch_train_loss = train_loss / len(train_dataloader)\n","    batch_train_accuracy = train_accuracy / len(train_dataloader)\n","\n","    #評価モードに設定\n","    net.eval()\n","    #評価時に自動微分をゼロにする\n","    with torch.no_grad():\n","        for x, y in val_dataloader:\n","\n","            # GPUヘ転送\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            #データを入力して予測値を計算\n","            preds = net(x)\n","            predlabels = torch.max(preds, 1)[1] # 予測ラベル導出\n","            #損失を計算\n","            loss = criterion(preds, y)\n","            #ミニバッチごとの損失と精度を備蓄\n","            val_loss += loss.item()\n","            val_accuracy += (y == predlabels).sum() / batch_size\n","\n","    #ミニバッチの平均の損失と正解率を計算\n","    batch_val_loss = val_loss / len(val_dataloader)\n","    batch_val_accuracy = val_accuracy / len(val_dataloader)\n","    #エポックごとに損失と正解率を表示\n","    print(\"Train_Loss: {:.4f} Train_Accuracy: {:.4f}\".format(batch_train_loss, batch_train_accuracy))\n","    print(\"Val_Loss: {:.4f} Val_Accuracy: {:.4f}\".format(batch_val_loss, batch_val_accuracy))\n","    #損失と正解率をリスト化して保存\n","    train_loss_list.append(batch_train_loss)\n","    #train_accuracy_list.append(batch_train_accuracy)\n","    train_accuracy_list.append(batch_train_accuracy.cpu())\n","    val_loss_list.append(batch_val_loss)\n","    #val_accuracy_list.append(batch_val_accuracy)\n","    val_accuracy_list.append(batch_val_accuracy.cpu())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pCPOKKaYzdO"},"source":["## 評価"]},{"cell_type":"code","metadata":{"id":"nLy1NFLsLolB"},"source":["# 損失関数\n","plt.figure(figsize=(15, 8))\n","plt.plot(train_loss_list, color='b', label='Train_Loss')\n","plt.plot(val_loss_list, color='m', label='val_loss')\n","plt.legend()\n","\n","# 精度\n","plt.figure(figsize=(15, 8))\n","plt.plot(train_accuracy_list, color='b', label='Train_Accuracy')\n","plt.plot(val_accuracy_list, color='m', label='val_accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cczf1ing2CJy"},"source":["(参考)予測をしてみる"]},{"cell_type":"code","metadata":{"id":"azKldWTyweX7"},"source":["# 検証データn番目の画像で予測してみる\n","n = 0\n","\n","# モデルを評価モードにする\n","net.eval()\n","\n","y_pred = None\n","images = None\n","labels = None\n","\n","# 検証用データローダからデータを一つのバッチだけ取り出す\n","with torch.no_grad():\n","  for x, y in val_dataloader:\n","    images = x\n","    labels = y\n","    break\n","\n","# 予測を実行する\n","images = images.to(device)\n","pred = net(images)\n","pred =pred.to('cpu').detach().numpy().copy()\n","prediction = np.argmax(pred, axis=1)\n","\n","# 画像をnumpyに直して表示できるようにしておく\n","images = images.to('cpu').detach().numpy().copy()\n","\n","plt.title(f'pred:{prediction[n]} / coll:{labels[n]}')   # ラベルを設定\n","plt.imshow(images[n].reshape((28, 28)), vmin=0, vmax=1, cmap=plt.cm.gray_r) # 画像を表示\n","plt.show()"],"execution_count":null,"outputs":[]}]}